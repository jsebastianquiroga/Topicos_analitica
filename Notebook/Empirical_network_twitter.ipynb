{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "m4cmOojch_to",
        "gKiIShYiXv1C",
        "ydlq9_vRaUdQ",
        "yfxtbQ_2ZrWL"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jsebastianquiroga/Topicos_analitica/blob/main/Notebook/Empirical_network_twitter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <img style=\"float: center; padding-right: 10px;\" src=\"https://www.pikpng.com/pngl/b/467-4670553_universidad-javeriana-esslingen-am-neckar-clipart.png\" width=\"100\" height=\"150\">\n",
        "\n",
        "\n",
        "\n",
        "<h1> <strong>Tópicos avanzados en analítica.</strong></h1> \n",
        "<h2> Para: Luis Gabriel Moreno Sandoval.</br></h2>\n",
        "<h2>Integrantes:</br></h2>\n",
        "<h2>Alejandro Vivas.</br></h2>\n",
        "<h2>Johan Sebastian Muñoz.</br></h2>\n",
        "<h2>Juan Sebastián Quiroga Bernal. </h2>"
      ],
      "metadata": {
        "id": "nzIeTlLbgD6s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> <strong>Workshop 1: Empirical Network  - Twitter.</strong></h1> \n",
        "\n",
        "En el presnte Notebook, se desarrollar una funcion que permita extraer los tuits que se desen con la API de snscrape.\n",
        "\n",
        "\n",
        "Este docuemnto esta dividio en las siguientes partes:\n",
        "<ol>\n",
        "<li> Funcion - Extraer Tuits.. </li>\n",
        "<li> Creación de Red de los Hastags. </li>\n",
        "<li> Creación de Red que asocie las palabras mas usadas. </li>\n",
        "<li> Conclusiones.</li>\n",
        "</ol>\n",
        "\n",
        "***"
      ],
      "metadata": {
        "id": "msRcJntlh-dN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install snscrape"
      ],
      "metadata": {
        "id": "zoLvhMAu4eBN",
        "outputId": "3890f032-e7c3-4266-c0c2-6cf5c0110ca0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: snscrape in /usr/local/lib/python3.9/dist-packages (0.6.1.20230314)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.9/dist-packages (from snscrape) (2.27.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from snscrape) (4.11.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from snscrape) (3.10.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.9/dist-packages (from snscrape) (4.9.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->snscrape) (2.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->snscrape) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->snscrape) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->snscrape) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->snscrape) (3.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->snscrape) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creación de funcion.\n",
        "\n",
        "#import the libraries to be use.\n",
        "import snscrape.modules.twitter as sntwitter\n",
        "import pandas as pd\n",
        "\n",
        "query = \"ptyhon\"\n",
        "tweets = []\n",
        "limits = 100\n",
        "\n",
        "for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
        "\n",
        "  if len(tweets) == limits:\n",
        "    break\n",
        "  else:\n",
        "    tweets.append([tweet.date, tweet.user.username, tweet.content])\n",
        "\n",
        "df =pd.DataFrame(tweets, columns =['Date', 'User', 'Tweet'])\n",
        "\n",
        "df\n",
        "\n",
        "  # print(vars(tweet))\n"
      ],
      "metadata": {
        "id": "rH5wGTQb4d58",
        "outputId": "85ee5f86-31d1-4842-dd6f-e181f78c84c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        }
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-75-dd5c721e3a40>:16: DeprecatedFeatureWarning:\n",
            "\n",
            "content is deprecated, use rawContent instead\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        Date            User  \\\n",
              "0  2023-03-18 14:44:10+00:00         Ptyhon1   \n",
              "1  2023-03-18 14:26:37+00:00         Ptyhon1   \n",
              "2  2023-03-18 12:59:23+00:00         Ptyhon1   \n",
              "3  2023-03-18 12:56:59+00:00         Ptyhon1   \n",
              "4  2023-03-18 12:56:06+00:00         Ptyhon1   \n",
              "..                       ...             ...   \n",
              "95 2023-02-11 16:54:58+00:00   yurideveloper   \n",
              "96 2023-02-09 12:02:13+00:00  juliancamposes   \n",
              "97 2023-02-06 20:29:32+00:00        rekman56   \n",
              "98 2023-01-28 23:27:13+00:00  roolbackgramer   \n",
              "99 2023-01-26 15:27:24+00:00       gkhanet06   \n",
              "\n",
              "                                                Tweet  \n",
              "0   @gknhrs @jahreindota @kadir_akgn81 Kanka afede...  \n",
              "1   @ugurmtr @Enesrn34 @bgyether Uğur kastığın duy...  \n",
              "2   @BAlpargu @karargah_haber Tayyip gitsin diye s...  \n",
              "3   @solcugazete Mankeni sikemediği için sinirlene...  \n",
              "4   @jahreindota Ne demeh yeri yoh yav cennet anal...  \n",
              "..                                                ...  \n",
              "95  Todo desenvolvedor precisa de uma linguagem de...  \n",
              "96  ¿Quieres una aplicación más al detalle de por ...  \n",
              "97  for i in range(1,24):\\ntsais le mec qui confon...  \n",
              "98  動的言語　Rubyをやっても日本全国には仕事がない。せいぜい東京のWeb限定の中小企業のみだ...  \n",
              "99                           Message sent from ptyhon  \n",
              "\n",
              "[100 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ba2c04dc-066a-4fb2-b96e-8695ddf598b4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>User</th>\n",
              "      <th>Tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2023-03-18 14:44:10+00:00</td>\n",
              "      <td>Ptyhon1</td>\n",
              "      <td>@gknhrs @jahreindota @kadir_akgn81 Kanka afede...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2023-03-18 14:26:37+00:00</td>\n",
              "      <td>Ptyhon1</td>\n",
              "      <td>@ugurmtr @Enesrn34 @bgyether Uğur kastığın duy...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2023-03-18 12:59:23+00:00</td>\n",
              "      <td>Ptyhon1</td>\n",
              "      <td>@BAlpargu @karargah_haber Tayyip gitsin diye s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2023-03-18 12:56:59+00:00</td>\n",
              "      <td>Ptyhon1</td>\n",
              "      <td>@solcugazete Mankeni sikemediği için sinirlene...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2023-03-18 12:56:06+00:00</td>\n",
              "      <td>Ptyhon1</td>\n",
              "      <td>@jahreindota Ne demeh yeri yoh yav cennet anal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>2023-02-11 16:54:58+00:00</td>\n",
              "      <td>yurideveloper</td>\n",
              "      <td>Todo desenvolvedor precisa de uma linguagem de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>2023-02-09 12:02:13+00:00</td>\n",
              "      <td>juliancamposes</td>\n",
              "      <td>¿Quieres una aplicación más al detalle de por ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>2023-02-06 20:29:32+00:00</td>\n",
              "      <td>rekman56</td>\n",
              "      <td>for i in range(1,24):\\ntsais le mec qui confon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>2023-01-28 23:27:13+00:00</td>\n",
              "      <td>roolbackgramer</td>\n",
              "      <td>動的言語　Rubyをやっても日本全国には仕事がない。せいぜい東京のWeb限定の中小企業のみだ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>2023-01-26 15:27:24+00:00</td>\n",
              "      <td>gkhanet06</td>\n",
              "      <td>Message sent from ptyhon</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ba2c04dc-066a-4fb2-b96e-8695ddf598b4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ba2c04dc-066a-4fb2-b96e-8695ddf598b4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ba2c04dc-066a-4fb2-b96e-8695ddf598b4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2"
      ],
      "metadata": {
        "id": "5aX3eBi6YuIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import snscrape.modules.twitter as sntwitter\n",
        "import networkx as nx\n",
        "import plotly.graph_objects as go\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "import snscrape.modules.twitter as sntwitter\n",
        "import networkx as nx\n",
        "import plotly.graph_objects as go\n",
        "import re\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import datetime as dt\n",
        "import pytz\n",
        "\n",
        "class TwitterGraph:\n",
        "    def __init__(self, query, search_method, max_tweets=100, start_date=None, end_date=None):\n",
        "        self.query = query\n",
        "        self.search_method = search_method\n",
        "        self.max_tweets = max_tweets\n",
        "        self.start_date = start_date\n",
        "        self.end_date = end_date\n",
        "        self.graph = nx.Graph()\n",
        "        self.data = None\n",
        "\n",
        "    def _scrape_tweets(self):\n",
        "        # construct search query based on search method and time range filters\n",
        "        if self.start_date and self.end_date:\n",
        "            date_range_query = f'since:{self.start_date} until:{self.end_date}'\n",
        "            search_query = f'{self.query} {date_range_query}'\n",
        "        else:\n",
        "            search_query = self.query\n",
        "\n",
        "        # create a scraper object based on the search method\n",
        "        if self.search_method == 'keyword':\n",
        "            scraper = sntwitter.TwitterSearchScraper(search_query)\n",
        "        elif self.search_method == 'hashtag':\n",
        "            scraper = sntwitter.TwitterSearchScraper(f'#{search_query}')\n",
        "        elif self.search_method == 'username':\n",
        "            scraper = sntwitter.TwitterUserScraper(search_query)\n",
        "        elif self.search_method == 'list':\n",
        "            scraper = sntwitter.TwitterListScraper(search_query)\n",
        "        elif self.search_method == 'advanced':\n",
        "            scraper = sntwitter.TwitterSearchScraper(search_query)\n",
        "        elif self.search_method == 'location':\n",
        "            scraper = sntwitter.TwitterSearchScraper(search_query)\n",
        "        else:\n",
        "            raise ValueError(\"Invalid search_method. Must be 'keyword', 'hashtag', 'username', 'list', 'advanced', or 'location'.\")\n",
        "\n",
        "        tweets = []\n",
        "        count = 0\n",
        "        # fetch tweets until we reach the desired number of tweets\n",
        "        for tweet in scraper.get_items():\n",
        "            if count >= self.max_tweets:\n",
        "                break\n",
        "            tweets.append(tweet)\n",
        "            count += 1\n",
        "\n",
        "        # filter tweets by date range if start_date and end_date are specified\n",
        "        if self.start_date and self.end_date:\n",
        "            start_date_dt = dt.datetime.strptime(self.start_date, '%Y-%m-%d').replace(tzinfo=pytz.UTC)\n",
        "            end_date_dt = dt.datetime.strptime(self.end_date, '%Y-%m-%d').replace(tzinfo=pytz.UTC)\n",
        "            filtered_tweets = []\n",
        "            for tweet in tweets:\n",
        "                if tweet.date >= start_date_dt and tweet.date <= end_date_dt:\n",
        "                    filtered_tweets.append(tweet)\n",
        "            tweets = filtered_tweets\n",
        "\n",
        "        # extract tweet information\n",
        "        data = []\n",
        "        for tweet in tweets:\n",
        "            # extract hashtags\n",
        "            hashtags = re.findall(r'#\\w+', tweet.rawContent)\n",
        "            for i, h1 in enumerate(hashtags):\n",
        "                for h2 in hashtags[i+1:]:\n",
        "                    # create an edge between users who have used the same hashtag\n",
        "                    self.graph.add_edge(tweet.user.username, h1)\n",
        "                    self.graph.add_edge(tweet.user.username, h2)\n",
        "            \n",
        "            data.append({\n",
        "                'tweet_id': tweet.id,\n",
        "                'username': tweet.user.username,\n",
        "                'Replay_to':tweet.inReplyToUser,\n",
        "                'user_mentioned': tweet.mentionedUsers,\n",
        "                'retweet' : tweet.retweetedTweet,\n",
        "                'quoted_tweet' : tweet.quotedTweet,\n",
        "                'content': tweet.rawContent,\n",
        "                'date': tweet.date,\n",
        "                'retweets': tweet.retweetCount,\n",
        "                'likes': tweet.likeCount,\n",
        "                'quotes': tweet.quoteCount,\n",
        "                'replies': tweet.replyCount,\n",
        "                'url': tweet.url,\n",
        "                'place': tweet.place,\n",
        "                'hashtags': tweet.hashtags,\n",
        "                'cashtags' : tweet.cashtags\n",
        "            })\n",
        "\n",
        "        # Create a DataFrame from the extracted data\n",
        "        self.data = pd.DataFrame(data)\n",
        "        return data\n",
        "\n",
        "    def build_graph(self):\n",
        "        self._scrape_tweets()\n",
        "        self.graph.remove_nodes_from(list(nx.isolates(self.graph)))\n",
        "\n",
        "        # compute node positions for the graph\n",
        "        node_positions = nx.spring_layout(self.graph)\n",
        "\n",
        "        # create a dictionary that maps usernames to node positions\n",
        "        user_positions = {}\n",
        "        for node, pos in node_positions.items():\n",
        "            user_positions[node] = pos\n",
        "            self.graph.nodes[node]['pos'] = pos\n",
        "\n",
        "        return user_positions\n",
        "        \n",
        "    def visualize_graph(self):\n",
        "        # get the node positions from the built graph\n",
        "        node_positions = self.build_graph()\n",
        "\n",
        "        # create a dataframe from the node positions\n",
        "        pos_df = pd.DataFrame(node_positions, index=['x', 'y']).T\n",
        "        pos_df.index.name = 'node'\n",
        "\n",
        "        # add the node positions to the graph\n",
        "        nx.set_node_attributes(self.graph, pos_df.to_dict('index'))\n",
        "\n",
        "        # create a plotly figure object\n",
        "        fig = px.scatter(pos_df, x='x', y='y', text=pos_df.index, custom_data=[pos_df.index])\n",
        "\n",
        "        # add edges to the figure\n",
        "        for edge in self.graph.edges:\n",
        "            x0, y0 = self.graph.nodes[edge[0]]['x'], self.graph.nodes[edge[0]]['y']\n",
        "            x1, y1 = self.graph.nodes[edge[1]]['x'], self.graph.nodes[edge[1]]['y']\n",
        "            fig.add_trace(\n",
        "                go.Scatter(x=[x0, x1], y=[y0, y1], mode='lines', line=dict(color='gray'))\n",
        "            )\n",
        "\n",
        "        # configure the figure layout\n",
        "        fig.update_traces(textposition='top center', marker=dict(size=10, color='lightblue'), hovertemplate='Username: %{customdata[0]}<extra></extra>')\n",
        "        fig.update_layout(title=f'Twitter Graph for {self.query}', title_font_size=30,\n",
        "                          xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
        "                          yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
        "                          hovermode='closest')\n",
        "\n",
        "        # display the figure\n",
        "        fig.show()"
      ],
      "metadata": {
        "id": "Fe2akOHpWYZy"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the TwitterGraph class with the desired parameters\n",
        "tg = TwitterGraph(query='Chelsea', search_method='hashtag', max_tweets=10, start_date='2023-03-15', end_date='2023-03-18')\n",
        "tweet = tg._scrape_tweets()\n",
        "#df = pd.DataFrame(tweet)\n",
        "#df.user_mentioned = df.user_mentioned.iloc[:][0].username\n",
        "#df\n",
        "tweet\n",
        "\n"
      ],
      "metadata": {
        "id": "N0B4L638fVx-",
        "outputId": "6e522a55-79b2-44bc-d626-1cc88360e038",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'tweet_id': 1636878854638673923,\n",
              "  'username': 'transfer_review',\n",
              "  'Replay_to': None,\n",
              "  'user_mentioned': [User(username='MattHughesDM', id=96757955, displayname='Matt Hughes', rawDescription=None, renderedDescription=None, descriptionLinks=None, verified=None, created=None, followersCount=None, friendsCount=None, statusesCount=None, favouritesCount=None, listedCount=None, mediaCount=None, location=None, protected=None, link=None, profileImageUrl=None, profileBannerUrl=None, label=None)],\n",
              "  'retweet': None,\n",
              "  'quoted_tweet': None,\n",
              "  'content': '#MasonMount has appointed a new agent, Neil Fewings from Wasserman Media Group, to manage a potential transfer from #Chelsea — the strongest indication yet that he is set to leave #StamfordBridge at the end of the season.\\n\\n(@MattHughesDM)\\n\\n#PL #Transfers\\nhttps://t.co/sRUGtnznxd',\n",
              "  'date': datetime.datetime(2023, 3, 17, 23, 55, 5, tzinfo=datetime.timezone.utc),\n",
              "  'retweets': 0,\n",
              "  'likes': 0,\n",
              "  'quotes': 0,\n",
              "  'replies': 1,\n",
              "  'url': 'https://twitter.com/transfer_review/status/1636878854638673923',\n",
              "  'place': None,\n",
              "  'hashtags': ['MasonMount', 'Chelsea', 'StamfordBridge', 'PL', 'Transfers'],\n",
              "  'cashtags': None},\n",
              " {'tweet_id': 1636877903295119362,\n",
              "  'username': 'Domenic36396232',\n",
              "  'Replay_to': None,\n",
              "  'user_mentioned': [User(username='TuttoMercatoWeb', id=412498166, displayname='TUTTOmercatoWEB', rawDescription=None, renderedDescription=None, descriptionLinks=None, verified=None, created=None, followersCount=None, friendsCount=None, statusesCount=None, favouritesCount=None, listedCount=None, mediaCount=None, location=None, protected=None, link=None, profileImageUrl=None, profileBannerUrl=None, label=None)],\n",
              "  'retweet': None,\n",
              "  'quoted_tweet': None,\n",
              "  'content': \"Porte girevoli in casa #Chelsea\\n#Mendy verso l'addio a fine stagione\\nStuzzica il nome di #Onana dell'#Inter\\n[ @TuttoMercatoWeb ]\\n\\n#Calciomercato \\n#Transfers\\n#PremierLeague \\n#StayTuned\",\n",
              "  'date': datetime.datetime(2023, 3, 17, 23, 51, 18, tzinfo=datetime.timezone.utc),\n",
              "  'retweets': 1,\n",
              "  'likes': 2,\n",
              "  'quotes': 0,\n",
              "  'replies': 0,\n",
              "  'url': 'https://twitter.com/Domenic36396232/status/1636877903295119362',\n",
              "  'place': None,\n",
              "  'hashtags': ['Chelsea',\n",
              "   'Mendy',\n",
              "   'Onana',\n",
              "   'Inter',\n",
              "   'Calciomercato',\n",
              "   'Transfers',\n",
              "   'PremierLeague',\n",
              "   'StayTuned'],\n",
              "  'cashtags': None},\n",
              " {'tweet_id': 1636877788497027072,\n",
              "  'username': '100B_Chelsea',\n",
              "  'Replay_to': None,\n",
              "  'user_mentioned': None,\n",
              "  'retweet': None,\n",
              "  'quoted_tweet': None,\n",
              "  'content': \"📰 - Mason #Mount a engagé un nouvel agent (en plus de son père), ce qui indique clairement qu'il pourrait quitter #Chelsea.\\n\\nChelsea insiste sur le fait qu'ils ont fait leur dernière offre à Mount, Mason et son père ont maintenant cherché une assistance plus spécialisée pour… https://t.co/qVQLZFOGeM\",\n",
              "  'date': datetime.datetime(2023, 3, 17, 23, 50, 51, tzinfo=datetime.timezone.utc),\n",
              "  'retweets': 19,\n",
              "  'likes': 231,\n",
              "  'quotes': 37,\n",
              "  'replies': 27,\n",
              "  'url': 'https://twitter.com/100B_Chelsea/status/1636877788497027072',\n",
              "  'place': None,\n",
              "  'hashtags': ['Mount', 'Chelsea'],\n",
              "  'cashtags': None},\n",
              " {'tweet_id': 1636877706435371008,\n",
              "  'username': 'BabilonBetcom',\n",
              "  'Replay_to': None,\n",
              "  'user_mentioned': [User(username='BabilonBetcom', id=1576227593342386177, displayname='BabilonBet', rawDescription=None, renderedDescription=None, descriptionLinks=None, verified=None, created=None, followersCount=None, friendsCount=None, statusesCount=None, favouritesCount=None, listedCount=None, mediaCount=None, location=None, protected=None, link=None, profileImageUrl=None, profileBannerUrl=None, label=None)],\n",
              "  'retweet': None,\n",
              "  'quoted_tweet': None,\n",
              "  'content': \"⚽️#Chelsea🆚#Everton Günün Maçı \\n@BabilonBetcom 'da\\n\\n📢#PremierLig heyecanı tüm hızı ile devam ediyor! En yüksek oranlar #BabilonBet' te seni bekliyor! \\n\\n🎁Hemen Gel %100 Spor Hoşgeldin Bonusunu Kap!\\n\\n💻Güncel Giriş: https://t.co/OZmZVgUmCh\\n#babilonbet #babilongiriş https://t.co/n730huH557\",\n",
              "  'date': datetime.datetime(2023, 3, 17, 23, 50, 31, tzinfo=datetime.timezone.utc),\n",
              "  'retweets': 0,\n",
              "  'likes': 0,\n",
              "  'quotes': 0,\n",
              "  'replies': 0,\n",
              "  'url': 'https://twitter.com/BabilonBetcom/status/1636877706435371008',\n",
              "  'place': None,\n",
              "  'hashtags': ['Chelsea',\n",
              "   'Everton',\n",
              "   'PremierLig',\n",
              "   'BabilonBet',\n",
              "   'babilonbet',\n",
              "   'babilongiriş'],\n",
              "  'cashtags': None},\n",
              " {'tweet_id': 1636876499310485505,\n",
              "  'username': 'Daniele20052013',\n",
              "  'Replay_to': None,\n",
              "  'user_mentioned': None,\n",
              "  'retweet': None,\n",
              "  'quoted_tweet': None,\n",
              "  'content': '#Calciomercato #Milan, il colpo arriva dal #Chelsea? Nel mirino per il centrocampo #LoftusCheek',\n",
              "  'date': datetime.datetime(2023, 3, 17, 23, 45, 43, tzinfo=datetime.timezone.utc),\n",
              "  'retweets': 0,\n",
              "  'likes': 0,\n",
              "  'quotes': 0,\n",
              "  'replies': 0,\n",
              "  'url': 'https://twitter.com/Daniele20052013/status/1636876499310485505',\n",
              "  'place': None,\n",
              "  'hashtags': ['Calciomercato', 'Milan', 'Chelsea', 'LoftusCheek'],\n",
              "  'cashtags': None},\n",
              " {'tweet_id': 1636876213070229506,\n",
              "  'username': 'TeamFootballFr',\n",
              "  'Replay_to': None,\n",
              "  'user_mentioned': [User(username='ThibaudVezirian', id=26835989, displayname='T.V.', rawDescription=None, renderedDescription=None, descriptionLinks=None, verified=None, created=None, followersCount=None, friendsCount=None, statusesCount=None, favouritesCount=None, listedCount=None, mediaCount=None, location=None, protected=None, link=None, profileImageUrl=None, profileBannerUrl=None, label=None)],\n",
              "  'retweet': None,\n",
              "  'quoted_tweet': None,\n",
              "  'content': '🔵⚪️ Le Racing Club de Strasbourg deviendra-t-il bientôt une filiale de #Chelsea ? \\n\\nhttps://t.co/oFbf6fwrMT\\n\\n#Boehly | #RCS | #RCSAAJA | #Strasbourg | #MarcKeller | @ThibaudVezirian',\n",
              "  'date': datetime.datetime(2023, 3, 17, 23, 44, 35, tzinfo=datetime.timezone.utc),\n",
              "  'retweets': 0,\n",
              "  'likes': 0,\n",
              "  'quotes': 0,\n",
              "  'replies': 0,\n",
              "  'url': 'https://twitter.com/TeamFootballFr/status/1636876213070229506',\n",
              "  'place': None,\n",
              "  'hashtags': ['Chelsea',\n",
              "   'Boehly',\n",
              "   'RCS',\n",
              "   'RCSAAJA',\n",
              "   'Strasbourg',\n",
              "   'MarcKeller'],\n",
              "  'cashtags': None},\n",
              " {'tweet_id': 1636875315661217795,\n",
              "  'username': 'CFCWajid',\n",
              "  'Replay_to': None,\n",
              "  'user_mentioned': None,\n",
              "  'retweet': None,\n",
              "  'quoted_tweet': None,\n",
              "  'content': \"I'm simply not worried about Real Madrid.\\n\\nWe literally going to have our best player of this competition fit and available to play. Bring it on! 👊💙\\n\\n#Cfc #Chelsea https://t.co/2qCH3vKLFv\",\n",
              "  'date': datetime.datetime(2023, 3, 17, 23, 41, 1, tzinfo=datetime.timezone.utc),\n",
              "  'retweets': 0,\n",
              "  'likes': 2,\n",
              "  'quotes': 0,\n",
              "  'replies': 0,\n",
              "  'url': 'https://twitter.com/CFCWajid/status/1636875315661217795',\n",
              "  'place': None,\n",
              "  'hashtags': ['Cfc', 'Chelsea'],\n",
              "  'cashtags': None},\n",
              " {'tweet_id': 1636874182343512067,\n",
              "  'username': 'latabernablue',\n",
              "  'Replay_to': None,\n",
              "  'user_mentioned': [User(username='MattHughesDM', id=96757955, displayname='Matt Hughes', rawDescription=None, renderedDescription=None, descriptionLinks=None, verified=None, created=None, followersCount=None, friendsCount=None, statusesCount=None, favouritesCount=None, listedCount=None, mediaCount=None, location=None, protected=None, link=None, profileImageUrl=None, profileBannerUrl=None, label=None),\n",
              "   User(username='MailSport', id=111556576, displayname='MailOnline Sport', rawDescription=None, renderedDescription=None, descriptionLinks=None, verified=None, created=None, followersCount=None, friendsCount=None, statusesCount=None, favouritesCount=None, listedCount=None, mediaCount=None, location=None, protected=None, link=None, profileImageUrl=None, profileBannerUrl=None, label=None)],\n",
              "  'retweet': None,\n",
              "  'quoted_tweet': None,\n",
              "  'content': 'Mason Mount contrata a un nuevo agente y sería una indicación fuerte de que podría abandonar el #Chelsea. \\n\\n-@MattHughesDM y @MailSport  #CFC',\n",
              "  'date': datetime.datetime(2023, 3, 17, 23, 36, 31, tzinfo=datetime.timezone.utc),\n",
              "  'retweets': 2,\n",
              "  'likes': 60,\n",
              "  'quotes': 1,\n",
              "  'replies': 4,\n",
              "  'url': 'https://twitter.com/latabernablue/status/1636874182343512067',\n",
              "  'place': None,\n",
              "  'hashtags': ['Chelsea', 'CFC'],\n",
              "  'cashtags': None},\n",
              " {'tweet_id': 1636873878931636230,\n",
              "  'username': 'Steven_123f',\n",
              "  'Replay_to': None,\n",
              "  'user_mentioned': None,\n",
              "  'retweet': None,\n",
              "  'quoted_tweet': None,\n",
              "  'content': '🚨Si buscas un servidor de #IPTV sólido,estable y sin interrupciones \\n\\n✅+10000 canales de TV internacionales\\n✅+25000 películas\\n✅Serie+2000\\n✅Alta calidad y estabilidad\\n✅FullHD y4K \\n\\nWhatsApp📲 https://t.co/lgl0nNjwiI\\n\\n#espana #RealMadrid #nantes #Chelsea #bayern #barca #liyon https://t.co/TVjF2uvlGj',\n",
              "  'date': datetime.datetime(2023, 3, 17, 23, 35, 19, tzinfo=datetime.timezone.utc),\n",
              "  'retweets': 0,\n",
              "  'likes': 0,\n",
              "  'quotes': 0,\n",
              "  'replies': 0,\n",
              "  'url': 'https://twitter.com/Steven_123f/status/1636873878931636230',\n",
              "  'place': None,\n",
              "  'hashtags': ['IPTV',\n",
              "   'espana',\n",
              "   'RealMadrid',\n",
              "   'nantes',\n",
              "   'Chelsea',\n",
              "   'bayern',\n",
              "   'barca',\n",
              "   'liyon'],\n",
              "  'cashtags': None},\n",
              " {'tweet_id': 1636873033779404801,\n",
              "  'username': 'Chelsbluesnews',\n",
              "  'Replay_to': None,\n",
              "  'user_mentioned': [User(username='Matt_Law_DT', id=130918844, displayname='Matt Law', rawDescription=None, renderedDescription=None, descriptionLinks=None, verified=None, created=None, followersCount=None, friendsCount=None, statusesCount=None, favouritesCount=None, listedCount=None, mediaCount=None, location=None, protected=None, link=None, profileImageUrl=None, profileBannerUrl=None, label=None)],\n",
              "  'retweet': None,\n",
              "  'quoted_tweet': None,\n",
              "  'content': 'Chelsea and England are in a dispute over Mason Mount with Chelsea pulling him out the squad - both sides eager to avoid having a row with each other @Matt_Law_DT #CFC #chelsea #england #mount',\n",
              "  'date': datetime.datetime(2023, 3, 17, 23, 31, 57, tzinfo=datetime.timezone.utc),\n",
              "  'retweets': 0,\n",
              "  'likes': 0,\n",
              "  'quotes': 0,\n",
              "  'replies': 0,\n",
              "  'url': 'https://twitter.com/Chelsbluesnews/status/1636873033779404801',\n",
              "  'place': None,\n",
              "  'hashtags': ['CFC', 'chelsea', 'england', 'mount'],\n",
              "  'cashtags': None}]"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for t in tweet:\n",
        "  for k,v t.items():\n",
        "    print(k,v)"
      ],
      "metadata": {
        "id": "KEFAXpZ8RTL_",
        "outputId": "a6efae69-1af0-4cef-a2b1-0a6ce7092f66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        }
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-104-2698fdccffb3>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    for k,v t.items():\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.user_mentioned"
      ],
      "metadata": {
        "id": "_IBIpXx_8yRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "re.findall(r'#[^\\s#]\\S*', df.content[1])"
      ],
      "metadata": {
        "id": "WGh3eZp1-dIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tg.build_graph()\n",
        "\n",
        "# Build and visualize the graph\n",
        "tg.visualize_graph()\n"
      ],
      "metadata": {
        "id": "hJzlC13m8QW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the TwitterGraph class with the desired parameters\n",
        "tg_1 = TwitterGraph(query='petrogustavo', search_method='username', max_tweets=20)#, start_date='2023-03-15', end_date='2023-03-18')\n",
        "tweet_1 = tg_1._scrape_tweets()\n",
        "df_1 = pd.DataFrame(tweet_1)\n",
        "df_1"
      ],
      "metadata": {
        "id": "mztZzaxcGcnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sntwitter"
      ],
      "metadata": {
        "id": "YLBsqXgDbDG5",
        "outputId": "73704112-8387-435e-8a71-bfef3b979739",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement sntwitter (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for sntwitter\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import datetime as dt\n",
        "import pytz\n",
        "import sntwitter\n",
        "import networkx as nx\n",
        "\n",
        "class TwitterScraper:\n",
        "    def __init__(self, search_method, query, max_tweets, start_date=None, end_date=None):\n",
        "        self.search_method = search_method\n",
        "        self.query = query\n",
        "        self.max_tweets = max_tweets\n",
        "        self.start_date = start_date\n",
        "        self.end_date = end_date\n",
        "        self.graph = nx.Graph()\n",
        "        \n",
        "    def _scrape_tweets(self):\n",
        "        # construct search query based on search method and time range filters\n",
        "        if self.start_date and self.end_date:\n",
        "            date_range_query = f'since:{self.start_date} until:{self.end_date}'\n",
        "            search_query = f'{self.query} {date_range_query}'\n",
        "        else:\n",
        "            search_query = self.query\n",
        "\n",
        "        # create a scraper object based on the search method\n",
        "        if self.search_method == 'keyword':\n",
        "            scraper = sntwitter.TwitterSearchScraper(search_query)\n",
        "            extract_function = lambda tweet: re.findall(r'\\b\\w+\\b', tweet.rawContent)\n",
        "        elif self.search_method == 'hashtag':\n",
        "            scraper = sntwitter.TwitterSearchScraper(f'#{search_query}')\n",
        "            extract_function = lambda tweet: tweet.hashtags\n",
        "        elif self.search_method == 'username':\n",
        "            scraper = sntwitter.TwitterUserScraper(search_query)\n",
        "            extract_function = lambda tweet: [tweet.user.username] + tweet.mentionedUsers + [tweet.inReplyToUser]\n",
        "        elif self.search_method == 'list':\n",
        "            scraper = sntwitter.TwitterListScraper(search_query)\n",
        "            extract_function = lambda tweet: re.findall(r'\\b\\w+\\b', tweet.rawContent)\n",
        "        elif self.search_method == 'advanced':\n",
        "            scraper = sntwitter.TwitterSearchScraper(search_query)\n",
        "            extract_function = lambda tweet: re.findall(r'\\b\\w+\\b', tweet.rawContent)\n",
        "        elif self.search_method == 'location':\n",
        "            scraper = sntwitter.TwitterSearchScraper(search_query)\n",
        "            extract_function = lambda tweet: tweet.place\n",
        "        else:\n",
        "            raise ValueError(\"Invalid search_method. Must be 'keyword', 'hashtag', 'username', 'list', 'advanced', or 'location'.\")\n",
        "\n",
        "        tweets = []\n",
        "        count = 0\n",
        "        # fetch tweets until we reach the desired number of tweets\n",
        "        for tweet in scraper.get_items():\n",
        "            if count >= self.max_tweets:\n",
        "                break\n",
        "            tweets.append(tweet)\n",
        "            count += 1\n",
        "\n",
        "        # extract tweet information and create edges between users\n",
        "        for tweet in tweets:\n",
        "            users = extract_function(tweet)\n",
        "            for i, u1 in enumerate(users):\n",
        "                for u2 in users[i+1:]:\n",
        "                    self.graph.add_edge(u1, u2)\n",
        "\n",
        "        # extract tweet information\n",
        "        data = []\n",
        "        for tweet in tweets:\n",
        "            data.append({\n",
        "                'tweet_id': tweet.id,\n",
        "                'username': tweet.user.username,\n",
        "                'Replay_to':tweet.inReplyToUser,\n",
        "                'user_mentioned': tweet.mentionedUsers,\n",
        "                'retweet' : tweet.retweetedTweet,\n",
        "                'quoted_tweet' : tweet.quotedTweet,\n",
        "                'content': tweet.rawContent,\n",
        "                'date': tweet.date,\n",
        "                'retweets': tweet.retweetCount,\n",
        "                'likes': tweet.likeCount,\n",
        "                'quotes': tweet.quoteCount,\n",
        "                'replies': tweet.replyCount,\n",
        "                'url': tweet.url,\n",
        "                'place': tweet.place,\n",
        "                'hashtags': tweet.hashtags,\n",
        "                'cashtags' : tweet.cashtags\n",
        "            })\n",
        "        # Create a DataFrame from the extracted data\n",
        "        self.data = pd.DataFrame(data)\n",
        "        return data\n",
        "\n",
        "    def build_graph(self):\n",
        "        self._scrape_tweets()\n",
        "        self.graph.remove_nodes_from(list(nx.isolates(self.graph)))\n",
        "\n",
        "        # compute node positions for the graph\n",
        "        node_positions = nx.spring_layout(self.graph)\n",
        "\n",
        "        # create a dictionary that maps usernames to node positions\n",
        "        user_positions = {}\n",
        "        for node, pos in node_positions.items():\n",
        "            user_positions[node] = pos\n",
        "            self.graph.nodes[node]['pos'] = pos\n",
        "\n",
        "        return user_positions\n",
        "        \n",
        "    def visualize_graph(self):\n",
        "        # get the node positions from the built graph\n",
        "        node_positions = self.build_graph()\n",
        "\n",
        "        # create a dataframe from the node positions\n",
        "        pos_df = pd.DataFrame(node_positions, index=['x', 'y']).T\n",
        "        pos_df.index.name = 'node'\n",
        "\n",
        "        # add the node positions to the graph\n",
        "        nx.set_node_attributes(self.graph, pos_df.to_dict('index'))\n",
        "\n",
        "        # create a plotly figure object\n",
        "        fig = px.scatter(pos_df, x='x', y='y', text=pos_df.index, custom_data=[pos_df.index])\n",
        "\n",
        "        # add edges to the figure\n",
        "        for edge in self.graph.edges:\n",
        "            x0, y0 = self.graph.nodes[edge[0]]['x'], self.graph.nodes[edge[0]]['y']\n",
        "            x1, y1 = self.graph.nodes[edge[1]]['x'], self.graph.nodes[edge[1]]['y']\n",
        "            fig.add_trace(\n",
        "                go.Scatter(x=[x0, x1], y=[y0, y1], mode='lines', line=dict(color='gray'))\n",
        "            )\n",
        "\n",
        "        # configure the figure layout\n",
        "        fig.update_traces(textposition='top center', marker=dict(size=10, color='lightblue'), hovertemplate='Username: %{customdata[0]}<extra></extra>')\n",
        "        fig.update_layout(title=f'Twitter Graph for {self.query}', title_font_size=30,\n",
        "                          xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
        "                          yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
        "                          hovermode='closest')\n",
        "\n",
        "        # display the figure\n",
        "        fig.show()"
      ],
      "metadata": {
        "id": "ugbXISi0ax4i",
        "outputId": "5c2a46e7-1a42-422e-a44e-1c3e7d583573",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-109-4fc152a925c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpytz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msntwitter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnetworkx\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sntwitter'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}