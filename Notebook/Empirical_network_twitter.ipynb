{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "m4cmOojch_to",
        "gKiIShYiXv1C",
        "ydlq9_vRaUdQ",
        "yfxtbQ_2ZrWL"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jsebastianquiroga/Topicos_analitica/blob/main/Notebook/Empirical_network_twitter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <img style=\"float: center; padding-right: 10px;\" src=\"https://www.pikpng.com/pngl/b/467-4670553_universidad-javeriana-esslingen-am-neckar-clipart.png\" width=\"100\" height=\"150\">\n",
        "\n",
        "\n",
        "\n",
        "<h1> <strong>T√≥picos avanzados en anal√≠tica.</strong></h1> \n",
        "<h2> Para: Luis Gabriel Moreno Sandoval.</br></h2>\n",
        "<h2>Integrantes:</br></h2>\n",
        "<h2>Alejandro Vivas.</br></h2>\n",
        "<h2>Johan Sebastian Mu√±oz.</br></h2>\n",
        "<h2>Juan Sebasti√°n Quiroga Bernal. </h2>"
      ],
      "metadata": {
        "id": "nzIeTlLbgD6s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> <strong>Workshop 1: Empirical Network  - Twitter.</strong></h1> \n",
        "\n",
        "En el presnte Notebook, se desarrollar una funcion que permita extraer los tuits que se desen con la API de snscrape.\n",
        "\n",
        "\n",
        "Este docuemnto esta dividio en las siguientes partes:\n",
        "<ol>\n",
        "<li> Funcion - Extraer Tuits.. </li>\n",
        "<li> Creaci√≥n de Red de los Hastags. </li>\n",
        "<li> Creaci√≥n de Red que asocie las palabras mas usadas. </li>\n",
        "<li> Conclusiones.</li>\n",
        "</ol>\n",
        "\n",
        "***"
      ],
      "metadata": {
        "id": "msRcJntlh-dN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install snscrape"
      ],
      "metadata": {
        "id": "zoLvhMAu4eBN",
        "outputId": "3890f032-e7c3-4266-c0c2-6cf5c0110ca0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: snscrape in /usr/local/lib/python3.9/dist-packages (0.6.1.20230314)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.9/dist-packages (from snscrape) (2.27.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from snscrape) (4.11.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from snscrape) (3.10.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.9/dist-packages (from snscrape) (4.9.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->snscrape) (2.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->snscrape) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->snscrape) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->snscrape) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->snscrape) (3.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->snscrape) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creaci√≥n de funcion.\n",
        "\n",
        "#import the libraries to be use.\n",
        "import snscrape.modules.twitter as sntwitter\n",
        "import pandas as pd\n",
        "\n",
        "query = \"ptyhon\"\n",
        "tweets = []\n",
        "limits = 100\n",
        "\n",
        "for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
        "\n",
        "  if len(tweets) == limits:\n",
        "    break\n",
        "  else:\n",
        "    tweets.append([tweet.date, tweet.user.username, tweet.content])\n",
        "\n",
        "df =pd.DataFrame(tweets, columns =['Date', 'User', 'Tweet'])\n",
        "\n",
        "df\n",
        "\n",
        "  # print(vars(tweet))\n"
      ],
      "metadata": {
        "id": "rH5wGTQb4d58",
        "outputId": "85ee5f86-31d1-4842-dd6f-e181f78c84c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        }
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-75-dd5c721e3a40>:16: DeprecatedFeatureWarning:\n",
            "\n",
            "content is deprecated, use rawContent instead\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        Date            User  \\\n",
              "0  2023-03-18 14:44:10+00:00         Ptyhon1   \n",
              "1  2023-03-18 14:26:37+00:00         Ptyhon1   \n",
              "2  2023-03-18 12:59:23+00:00         Ptyhon1   \n",
              "3  2023-03-18 12:56:59+00:00         Ptyhon1   \n",
              "4  2023-03-18 12:56:06+00:00         Ptyhon1   \n",
              "..                       ...             ...   \n",
              "95 2023-02-11 16:54:58+00:00   yurideveloper   \n",
              "96 2023-02-09 12:02:13+00:00  juliancamposes   \n",
              "97 2023-02-06 20:29:32+00:00        rekman56   \n",
              "98 2023-01-28 23:27:13+00:00  roolbackgramer   \n",
              "99 2023-01-26 15:27:24+00:00       gkhanet06   \n",
              "\n",
              "                                                Tweet  \n",
              "0   @gknhrs @jahreindota @kadir_akgn81 Kanka afede...  \n",
              "1   @ugurmtr @Enesrn34 @bgyether Uƒüur kastƒ±ƒüƒ±n duy...  \n",
              "2   @BAlpargu @karargah_haber Tayyip gitsin diye s...  \n",
              "3   @solcugazete Mankeni sikemediƒüi i√ßin sinirlene...  \n",
              "4   @jahreindota Ne demeh yeri yoh yav cennet anal...  \n",
              "..                                                ...  \n",
              "95  Todo desenvolvedor precisa de uma linguagem de...  \n",
              "96  ¬øQuieres una aplicaci√≥n m√°s al detalle de por ...  \n",
              "97  for i in range(1,24):\\ntsais le mec qui confon...  \n",
              "98  ÂãïÁöÑË®ÄË™û„ÄÄRuby„Çí„ÇÑ„Å£„Å¶„ÇÇÊó•Êú¨ÂÖ®ÂõΩ„Å´„ÅØ‰ªï‰∫ã„Åå„Å™„ÅÑ„ÄÇ„Åõ„ÅÑ„Åú„ÅÑÊù±‰∫¨„ÅÆWebÈôêÂÆö„ÅÆ‰∏≠Â∞è‰ºÅÊ•≠„ÅÆ„Åø„Å†...  \n",
              "99                           Message sent from ptyhon  \n",
              "\n",
              "[100 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ba2c04dc-066a-4fb2-b96e-8695ddf598b4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>User</th>\n",
              "      <th>Tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2023-03-18 14:44:10+00:00</td>\n",
              "      <td>Ptyhon1</td>\n",
              "      <td>@gknhrs @jahreindota @kadir_akgn81 Kanka afede...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2023-03-18 14:26:37+00:00</td>\n",
              "      <td>Ptyhon1</td>\n",
              "      <td>@ugurmtr @Enesrn34 @bgyether Uƒüur kastƒ±ƒüƒ±n duy...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2023-03-18 12:59:23+00:00</td>\n",
              "      <td>Ptyhon1</td>\n",
              "      <td>@BAlpargu @karargah_haber Tayyip gitsin diye s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2023-03-18 12:56:59+00:00</td>\n",
              "      <td>Ptyhon1</td>\n",
              "      <td>@solcugazete Mankeni sikemediƒüi i√ßin sinirlene...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2023-03-18 12:56:06+00:00</td>\n",
              "      <td>Ptyhon1</td>\n",
              "      <td>@jahreindota Ne demeh yeri yoh yav cennet anal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>2023-02-11 16:54:58+00:00</td>\n",
              "      <td>yurideveloper</td>\n",
              "      <td>Todo desenvolvedor precisa de uma linguagem de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>2023-02-09 12:02:13+00:00</td>\n",
              "      <td>juliancamposes</td>\n",
              "      <td>¬øQuieres una aplicaci√≥n m√°s al detalle de por ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>2023-02-06 20:29:32+00:00</td>\n",
              "      <td>rekman56</td>\n",
              "      <td>for i in range(1,24):\\ntsais le mec qui confon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>2023-01-28 23:27:13+00:00</td>\n",
              "      <td>roolbackgramer</td>\n",
              "      <td>ÂãïÁöÑË®ÄË™û„ÄÄRuby„Çí„ÇÑ„Å£„Å¶„ÇÇÊó•Êú¨ÂÖ®ÂõΩ„Å´„ÅØ‰ªï‰∫ã„Åå„Å™„ÅÑ„ÄÇ„Åõ„ÅÑ„Åú„ÅÑÊù±‰∫¨„ÅÆWebÈôêÂÆö„ÅÆ‰∏≠Â∞è‰ºÅÊ•≠„ÅÆ„Åø„Å†...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>2023-01-26 15:27:24+00:00</td>\n",
              "      <td>gkhanet06</td>\n",
              "      <td>Message sent from ptyhon</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows √ó 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ba2c04dc-066a-4fb2-b96e-8695ddf598b4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ba2c04dc-066a-4fb2-b96e-8695ddf598b4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ba2c04dc-066a-4fb2-b96e-8695ddf598b4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2"
      ],
      "metadata": {
        "id": "5aX3eBi6YuIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import snscrape.modules.twitter as sntwitter\n",
        "import networkx as nx\n",
        "import plotly.graph_objects as go\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "import snscrape.modules.twitter as sntwitter\n",
        "import networkx as nx\n",
        "import plotly.graph_objects as go\n",
        "import re\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import datetime as dt\n",
        "import pytz\n",
        "\n",
        "class TwitterGraph:\n",
        "    def __init__(self, query, search_method, max_tweets=100, start_date=None, end_date=None):\n",
        "        self.query = query\n",
        "        self.search_method = search_method\n",
        "        self.max_tweets = max_tweets\n",
        "        self.start_date = start_date\n",
        "        self.end_date = end_date\n",
        "        self.graph = nx.Graph()\n",
        "        self.data = None\n",
        "\n",
        "    def _scrape_tweets(self):\n",
        "        # construct search query based on search method and time range filters\n",
        "        if self.start_date and self.end_date:\n",
        "            date_range_query = f'since:{self.start_date} until:{self.end_date}'\n",
        "            search_query = f'{self.query} {date_range_query}'\n",
        "        else:\n",
        "            search_query = self.query\n",
        "\n",
        "        # create a scraper object based on the search method\n",
        "        if self.search_method == 'keyword':\n",
        "            scraper = sntwitter.TwitterSearchScraper(search_query)\n",
        "        elif self.search_method == 'hashtag':\n",
        "            scraper = sntwitter.TwitterSearchScraper(f'#{search_query}')\n",
        "        elif self.search_method == 'username':\n",
        "            scraper = sntwitter.TwitterUserScraper(search_query)\n",
        "        elif self.search_method == 'list':\n",
        "            scraper = sntwitter.TwitterListScraper(search_query)\n",
        "        elif self.search_method == 'advanced':\n",
        "            scraper = sntwitter.TwitterSearchScraper(search_query)\n",
        "        elif self.search_method == 'location':\n",
        "            scraper = sntwitter.TwitterSearchScraper(search_query)\n",
        "        else:\n",
        "            raise ValueError(\"Invalid search_method. Must be 'keyword', 'hashtag', 'username', 'list', 'advanced', or 'location'.\")\n",
        "\n",
        "        tweets = []\n",
        "        count = 0\n",
        "        # fetch tweets until we reach the desired number of tweets\n",
        "        for tweet in scraper.get_items():\n",
        "            if count >= self.max_tweets:\n",
        "                break\n",
        "            tweets.append(tweet)\n",
        "            count += 1\n",
        "\n",
        "        # filter tweets by date range if start_date and end_date are specified\n",
        "        if self.start_date and self.end_date:\n",
        "            start_date_dt = dt.datetime.strptime(self.start_date, '%Y-%m-%d').replace(tzinfo=pytz.UTC)\n",
        "            end_date_dt = dt.datetime.strptime(self.end_date, '%Y-%m-%d').replace(tzinfo=pytz.UTC)\n",
        "            filtered_tweets = []\n",
        "            for tweet in tweets:\n",
        "                if tweet.date >= start_date_dt and tweet.date <= end_date_dt:\n",
        "                    filtered_tweets.append(tweet)\n",
        "            tweets = filtered_tweets\n",
        "\n",
        "        # extract tweet information\n",
        "        data = []\n",
        "        for tweet in tweets:\n",
        "            # extract hashtags\n",
        "            hashtags = re.findall(r'#\\w+', tweet.rawContent)\n",
        "            for i, h1 in enumerate(hashtags):\n",
        "                for h2 in hashtags[i+1:]:\n",
        "                    # create an edge between users who have used the same hashtag\n",
        "                    self.graph.add_edge(tweet.user.username, h1)\n",
        "                    self.graph.add_edge(tweet.user.username, h2)\n",
        "            \n",
        "            data.append({\n",
        "                'tweet_id': tweet.id,\n",
        "                'username': tweet.user.username,\n",
        "                'Replay_to':tweet.inReplyToUser,\n",
        "                'user_mentioned': tweet.mentionedUsers,\n",
        "                'retweet' : tweet.retweetedTweet,\n",
        "                'quoted_tweet' : tweet.quotedTweet,\n",
        "                'content': tweet.rawContent,\n",
        "                'date': tweet.date,\n",
        "                'retweets': tweet.retweetCount,\n",
        "                'likes': tweet.likeCount,\n",
        "                'quotes': tweet.quoteCount,\n",
        "                'replies': tweet.replyCount,\n",
        "                'url': tweet.url,\n",
        "                'place': tweet.place,\n",
        "                'hashtags': tweet.hashtags,\n",
        "                'cashtags' : tweet.cashtags\n",
        "            })\n",
        "\n",
        "        # Create a DataFrame from the extracted data\n",
        "        self.data = pd.DataFrame(data)\n",
        "        return data\n",
        "\n",
        "    def build_graph(self):\n",
        "        self._scrape_tweets()\n",
        "        self.graph.remove_nodes_from(list(nx.isolates(self.graph)))\n",
        "\n",
        "        # compute node positions for the graph\n",
        "        node_positions = nx.spring_layout(self.graph)\n",
        "\n",
        "        # create a dictionary that maps usernames to node positions\n",
        "        user_positions = {}\n",
        "        for node, pos in node_positions.items():\n",
        "            user_positions[node] = pos\n",
        "            self.graph.nodes[node]['pos'] = pos\n",
        "\n",
        "        return user_positions\n",
        "        \n",
        "    def visualize_graph(self):\n",
        "        # get the node positions from the built graph\n",
        "        node_positions = self.build_graph()\n",
        "\n",
        "        # create a dataframe from the node positions\n",
        "        pos_df = pd.DataFrame(node_positions, index=['x', 'y']).T\n",
        "        pos_df.index.name = 'node'\n",
        "\n",
        "        # add the node positions to the graph\n",
        "        nx.set_node_attributes(self.graph, pos_df.to_dict('index'))\n",
        "\n",
        "        # create a plotly figure object\n",
        "        fig = px.scatter(pos_df, x='x', y='y', text=pos_df.index, custom_data=[pos_df.index])\n",
        "\n",
        "        # add edges to the figure\n",
        "        for edge in self.graph.edges:\n",
        "            x0, y0 = self.graph.nodes[edge[0]]['x'], self.graph.nodes[edge[0]]['y']\n",
        "            x1, y1 = self.graph.nodes[edge[1]]['x'], self.graph.nodes[edge[1]]['y']\n",
        "            fig.add_trace(\n",
        "                go.Scatter(x=[x0, x1], y=[y0, y1], mode='lines', line=dict(color='gray'))\n",
        "            )\n",
        "\n",
        "        # configure the figure layout\n",
        "        fig.update_traces(textposition='top center', marker=dict(size=10, color='lightblue'), hovertemplate='Username: %{customdata[0]}<extra></extra>')\n",
        "        fig.update_layout(title=f'Twitter Graph for {self.query}', title_font_size=30,\n",
        "                          xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
        "                          yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
        "                          hovermode='closest')\n",
        "\n",
        "        # display the figure\n",
        "        fig.show()"
      ],
      "metadata": {
        "id": "Fe2akOHpWYZy"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the TwitterGraph class with the desired parameters\n",
        "tg = TwitterGraph(query='Chelsea', search_method='hashtag', max_tweets=10, start_date='2023-03-15', end_date='2023-03-18')\n",
        "tweet = tg._scrape_tweets()\n",
        "#df = pd.DataFrame(tweet)\n",
        "#df.user_mentioned = df.user_mentioned.iloc[:][0].username\n",
        "#df\n",
        "tweet\n",
        "\n"
      ],
      "metadata": {
        "id": "N0B4L638fVx-",
        "outputId": "6e522a55-79b2-44bc-d626-1cc88360e038",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'tweet_id': 1636878854638673923,\n",
              "  'username': 'transfer_review',\n",
              "  'Replay_to': None,\n",
              "  'user_mentioned': [User(username='MattHughesDM', id=96757955, displayname='Matt Hughes', rawDescription=None, renderedDescription=None, descriptionLinks=None, verified=None, created=None, followersCount=None, friendsCount=None, statusesCount=None, favouritesCount=None, listedCount=None, mediaCount=None, location=None, protected=None, link=None, profileImageUrl=None, profileBannerUrl=None, label=None)],\n",
              "  'retweet': None,\n",
              "  'quoted_tweet': None,\n",
              "  'content': '#MasonMount has appointed a new agent, Neil Fewings from Wasserman Media Group, to manage a potential transfer from #Chelsea ‚Äî the strongest indication yet that he is set to leave #StamfordBridge at the end of the season.\\n\\n(@MattHughesDM)\\n\\n#PL #Transfers\\nhttps://t.co/sRUGtnznxd',\n",
              "  'date': datetime.datetime(2023, 3, 17, 23, 55, 5, tzinfo=datetime.timezone.utc),\n",
              "  'retweets': 0,\n",
              "  'likes': 0,\n",
              "  'quotes': 0,\n",
              "  'replies': 1,\n",
              "  'url': 'https://twitter.com/transfer_review/status/1636878854638673923',\n",
              "  'place': None,\n",
              "  'hashtags': ['MasonMount', 'Chelsea', 'StamfordBridge', 'PL', 'Transfers'],\n",
              "  'cashtags': None},\n",
              " {'tweet_id': 1636877903295119362,\n",
              "  'username': 'Domenic36396232',\n",
              "  'Replay_to': None,\n",
              "  'user_mentioned': [User(username='TuttoMercatoWeb', id=412498166, displayname='TUTTOmercatoWEB', rawDescription=None, renderedDescription=None, descriptionLinks=None, verified=None, created=None, followersCount=None, friendsCount=None, statusesCount=None, favouritesCount=None, listedCount=None, mediaCount=None, location=None, protected=None, link=None, profileImageUrl=None, profileBannerUrl=None, label=None)],\n",
              "  'retweet': None,\n",
              "  'quoted_tweet': None,\n",
              "  'content': \"Porte girevoli in casa #Chelsea\\n#Mendy verso l'addio a fine stagione\\nStuzzica il nome di #Onana dell'#Inter\\n[ @TuttoMercatoWeb ]\\n\\n#Calciomercato \\n#Transfers\\n#PremierLeague \\n#StayTuned\",\n",
              "  'date': datetime.datetime(2023, 3, 17, 23, 51, 18, tzinfo=datetime.timezone.utc),\n",
              "  'retweets': 1,\n",
              "  'likes': 2,\n",
              "  'quotes': 0,\n",
              "  'replies': 0,\n",
              "  'url': 'https://twitter.com/Domenic36396232/status/1636877903295119362',\n",
              "  'place': None,\n",
              "  'hashtags': ['Chelsea',\n",
              "   'Mendy',\n",
              "   'Onana',\n",
              "   'Inter',\n",
              "   'Calciomercato',\n",
              "   'Transfers',\n",
              "   'PremierLeague',\n",
              "   'StayTuned'],\n",
              "  'cashtags': None},\n",
              " {'tweet_id': 1636877788497027072,\n",
              "  'username': '100B_Chelsea',\n",
              "  'Replay_to': None,\n",
              "  'user_mentioned': None,\n",
              "  'retweet': None,\n",
              "  'quoted_tweet': None,\n",
              "  'content': \"üì∞ - Mason #Mount a engag√© un nouvel agent (en plus de son p√®re), ce qui indique clairement qu'il pourrait quitter #Chelsea.\\n\\nChelsea insiste sur le fait qu'ils ont fait leur derni√®re offre √† Mount, Mason et son p√®re ont maintenant cherch√© une assistance plus sp√©cialis√©e pour‚Ä¶ https://t.co/qVQLZFOGeM\",\n",
              "  'date': datetime.datetime(2023, 3, 17, 23, 50, 51, tzinfo=datetime.timezone.utc),\n",
              "  'retweets': 19,\n",
              "  'likes': 231,\n",
              "  'quotes': 37,\n",
              "  'replies': 27,\n",
              "  'url': 'https://twitter.com/100B_Chelsea/status/1636877788497027072',\n",
              "  'place': None,\n",
              "  'hashtags': ['Mount', 'Chelsea'],\n",
              "  'cashtags': None},\n",
              " {'tweet_id': 1636877706435371008,\n",
              "  'username': 'BabilonBetcom',\n",
              "  'Replay_to': None,\n",
              "  'user_mentioned': [User(username='BabilonBetcom', id=1576227593342386177, displayname='BabilonBet', rawDescription=None, renderedDescription=None, descriptionLinks=None, verified=None, created=None, followersCount=None, friendsCount=None, statusesCount=None, favouritesCount=None, listedCount=None, mediaCount=None, location=None, protected=None, link=None, profileImageUrl=None, profileBannerUrl=None, label=None)],\n",
              "  'retweet': None,\n",
              "  'quoted_tweet': None,\n",
              "  'content': \"‚öΩÔ∏è#ChelseaüÜö#Everton G√ºn√ºn Ma√ßƒ± \\n@BabilonBetcom 'da\\n\\nüì¢#PremierLig heyecanƒ± t√ºm hƒ±zƒ± ile devam ediyor! En y√ºksek oranlar #BabilonBet' te seni bekliyor! \\n\\nüéÅHemen Gel %100 Spor Ho≈ügeldin Bonusunu Kap!\\n\\nüíªG√ºncel Giri≈ü: https://t.co/OZmZVgUmCh\\n#babilonbet #babilongiri≈ü https://t.co/n730huH557\",\n",
              "  'date': datetime.datetime(2023, 3, 17, 23, 50, 31, tzinfo=datetime.timezone.utc),\n",
              "  'retweets': 0,\n",
              "  'likes': 0,\n",
              "  'quotes': 0,\n",
              "  'replies': 0,\n",
              "  'url': 'https://twitter.com/BabilonBetcom/status/1636877706435371008',\n",
              "  'place': None,\n",
              "  'hashtags': ['Chelsea',\n",
              "   'Everton',\n",
              "   'PremierLig',\n",
              "   'BabilonBet',\n",
              "   'babilonbet',\n",
              "   'babilongiri≈ü'],\n",
              "  'cashtags': None},\n",
              " {'tweet_id': 1636876499310485505,\n",
              "  'username': 'Daniele20052013',\n",
              "  'Replay_to': None,\n",
              "  'user_mentioned': None,\n",
              "  'retweet': None,\n",
              "  'quoted_tweet': None,\n",
              "  'content': '#Calciomercato #Milan, il colpo arriva dal #Chelsea? Nel mirino per il centrocampo #LoftusCheek',\n",
              "  'date': datetime.datetime(2023, 3, 17, 23, 45, 43, tzinfo=datetime.timezone.utc),\n",
              "  'retweets': 0,\n",
              "  'likes': 0,\n",
              "  'quotes': 0,\n",
              "  'replies': 0,\n",
              "  'url': 'https://twitter.com/Daniele20052013/status/1636876499310485505',\n",
              "  'place': None,\n",
              "  'hashtags': ['Calciomercato', 'Milan', 'Chelsea', 'LoftusCheek'],\n",
              "  'cashtags': None},\n",
              " {'tweet_id': 1636876213070229506,\n",
              "  'username': 'TeamFootballFr',\n",
              "  'Replay_to': None,\n",
              "  'user_mentioned': [User(username='ThibaudVezirian', id=26835989, displayname='T.V.', rawDescription=None, renderedDescription=None, descriptionLinks=None, verified=None, created=None, followersCount=None, friendsCount=None, statusesCount=None, favouritesCount=None, listedCount=None, mediaCount=None, location=None, protected=None, link=None, profileImageUrl=None, profileBannerUrl=None, label=None)],\n",
              "  'retweet': None,\n",
              "  'quoted_tweet': None,\n",
              "  'content': 'üîµ‚ö™Ô∏è Le Racing Club de Strasbourg deviendra-t-il bient√¥t une filiale de #Chelsea ? \\n\\nhttps://t.co/oFbf6fwrMT\\n\\n#Boehly | #RCS | #RCSAAJA | #Strasbourg | #MarcKeller | @ThibaudVezirian',\n",
              "  'date': datetime.datetime(2023, 3, 17, 23, 44, 35, tzinfo=datetime.timezone.utc),\n",
              "  'retweets': 0,\n",
              "  'likes': 0,\n",
              "  'quotes': 0,\n",
              "  'replies': 0,\n",
              "  'url': 'https://twitter.com/TeamFootballFr/status/1636876213070229506',\n",
              "  'place': None,\n",
              "  'hashtags': ['Chelsea',\n",
              "   'Boehly',\n",
              "   'RCS',\n",
              "   'RCSAAJA',\n",
              "   'Strasbourg',\n",
              "   'MarcKeller'],\n",
              "  'cashtags': None},\n",
              " {'tweet_id': 1636875315661217795,\n",
              "  'username': 'CFCWajid',\n",
              "  'Replay_to': None,\n",
              "  'user_mentioned': None,\n",
              "  'retweet': None,\n",
              "  'quoted_tweet': None,\n",
              "  'content': \"I'm simply not worried about Real Madrid.\\n\\nWe literally going to have our best player of this competition fit and available to play. Bring it on! üëäüíô\\n\\n#Cfc #Chelsea https://t.co/2qCH3vKLFv\",\n",
              "  'date': datetime.datetime(2023, 3, 17, 23, 41, 1, tzinfo=datetime.timezone.utc),\n",
              "  'retweets': 0,\n",
              "  'likes': 2,\n",
              "  'quotes': 0,\n",
              "  'replies': 0,\n",
              "  'url': 'https://twitter.com/CFCWajid/status/1636875315661217795',\n",
              "  'place': None,\n",
              "  'hashtags': ['Cfc', 'Chelsea'],\n",
              "  'cashtags': None},\n",
              " {'tweet_id': 1636874182343512067,\n",
              "  'username': 'latabernablue',\n",
              "  'Replay_to': None,\n",
              "  'user_mentioned': [User(username='MattHughesDM', id=96757955, displayname='Matt Hughes', rawDescription=None, renderedDescription=None, descriptionLinks=None, verified=None, created=None, followersCount=None, friendsCount=None, statusesCount=None, favouritesCount=None, listedCount=None, mediaCount=None, location=None, protected=None, link=None, profileImageUrl=None, profileBannerUrl=None, label=None),\n",
              "   User(username='MailSport', id=111556576, displayname='MailOnline Sport', rawDescription=None, renderedDescription=None, descriptionLinks=None, verified=None, created=None, followersCount=None, friendsCount=None, statusesCount=None, favouritesCount=None, listedCount=None, mediaCount=None, location=None, protected=None, link=None, profileImageUrl=None, profileBannerUrl=None, label=None)],\n",
              "  'retweet': None,\n",
              "  'quoted_tweet': None,\n",
              "  'content': 'Mason Mount contrata a un nuevo agente y ser√≠a una indicaci√≥n fuerte de que podr√≠a abandonar el #Chelsea. \\n\\n-@MattHughesDM y @MailSport  #CFC',\n",
              "  'date': datetime.datetime(2023, 3, 17, 23, 36, 31, tzinfo=datetime.timezone.utc),\n",
              "  'retweets': 2,\n",
              "  'likes': 60,\n",
              "  'quotes': 1,\n",
              "  'replies': 4,\n",
              "  'url': 'https://twitter.com/latabernablue/status/1636874182343512067',\n",
              "  'place': None,\n",
              "  'hashtags': ['Chelsea', 'CFC'],\n",
              "  'cashtags': None},\n",
              " {'tweet_id': 1636873878931636230,\n",
              "  'username': 'Steven_123f',\n",
              "  'Replay_to': None,\n",
              "  'user_mentioned': None,\n",
              "  'retweet': None,\n",
              "  'quoted_tweet': None,\n",
              "  'content': 'üö®Si buscas un servidor de #IPTV s√≥lido,estable y sin interrupciones \\n\\n‚úÖ+10000 canales de TV internacionales\\n‚úÖ+25000 pel√≠culas\\n‚úÖSerie+2000\\n‚úÖAlta calidad y estabilidad\\n‚úÖFullHD y4K \\n\\nWhatsAppüì≤ https://t.co/lgl0nNjwiI\\n\\n#espana #RealMadrid #nantes #Chelsea #bayern #barca #liyon https://t.co/TVjF2uvlGj',\n",
              "  'date': datetime.datetime(2023, 3, 17, 23, 35, 19, tzinfo=datetime.timezone.utc),\n",
              "  'retweets': 0,\n",
              "  'likes': 0,\n",
              "  'quotes': 0,\n",
              "  'replies': 0,\n",
              "  'url': 'https://twitter.com/Steven_123f/status/1636873878931636230',\n",
              "  'place': None,\n",
              "  'hashtags': ['IPTV',\n",
              "   'espana',\n",
              "   'RealMadrid',\n",
              "   'nantes',\n",
              "   'Chelsea',\n",
              "   'bayern',\n",
              "   'barca',\n",
              "   'liyon'],\n",
              "  'cashtags': None},\n",
              " {'tweet_id': 1636873033779404801,\n",
              "  'username': 'Chelsbluesnews',\n",
              "  'Replay_to': None,\n",
              "  'user_mentioned': [User(username='Matt_Law_DT', id=130918844, displayname='Matt Law', rawDescription=None, renderedDescription=None, descriptionLinks=None, verified=None, created=None, followersCount=None, friendsCount=None, statusesCount=None, favouritesCount=None, listedCount=None, mediaCount=None, location=None, protected=None, link=None, profileImageUrl=None, profileBannerUrl=None, label=None)],\n",
              "  'retweet': None,\n",
              "  'quoted_tweet': None,\n",
              "  'content': 'Chelsea and England are in a dispute over Mason Mount with Chelsea pulling him out the squad - both sides eager to avoid having a row with each other @Matt_Law_DT #CFC #chelsea #england #mount',\n",
              "  'date': datetime.datetime(2023, 3, 17, 23, 31, 57, tzinfo=datetime.timezone.utc),\n",
              "  'retweets': 0,\n",
              "  'likes': 0,\n",
              "  'quotes': 0,\n",
              "  'replies': 0,\n",
              "  'url': 'https://twitter.com/Chelsbluesnews/status/1636873033779404801',\n",
              "  'place': None,\n",
              "  'hashtags': ['CFC', 'chelsea', 'england', 'mount'],\n",
              "  'cashtags': None}]"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for t in tweet:\n",
        "  for k,v t.items():\n",
        "    print(k,v)"
      ],
      "metadata": {
        "id": "KEFAXpZ8RTL_",
        "outputId": "a6efae69-1af0-4cef-a2b1-0a6ce7092f66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        }
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-104-2698fdccffb3>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    for k,v t.items():\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.user_mentioned"
      ],
      "metadata": {
        "id": "_IBIpXx_8yRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "re.findall(r'#[^\\s#]\\S*', df.content[1])"
      ],
      "metadata": {
        "id": "WGh3eZp1-dIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tg.build_graph()\n",
        "\n",
        "# Build and visualize the graph\n",
        "tg.visualize_graph()\n"
      ],
      "metadata": {
        "id": "hJzlC13m8QW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the TwitterGraph class with the desired parameters\n",
        "tg_1 = TwitterGraph(query='petrogustavo', search_method='username', max_tweets=20)#, start_date='2023-03-15', end_date='2023-03-18')\n",
        "tweet_1 = tg_1._scrape_tweets()\n",
        "df_1 = pd.DataFrame(tweet_1)\n",
        "df_1"
      ],
      "metadata": {
        "id": "mztZzaxcGcnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sntwitter"
      ],
      "metadata": {
        "id": "YLBsqXgDbDG5",
        "outputId": "73704112-8387-435e-8a71-bfef3b979739",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement sntwitter (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for sntwitter\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import datetime as dt\n",
        "import pytz\n",
        "import sntwitter\n",
        "import networkx as nx\n",
        "\n",
        "class TwitterScraper:\n",
        "    def __init__(self, search_method, query, max_tweets, start_date=None, end_date=None):\n",
        "        self.search_method = search_method\n",
        "        self.query = query\n",
        "        self.max_tweets = max_tweets\n",
        "        self.start_date = start_date\n",
        "        self.end_date = end_date\n",
        "        self.graph = nx.Graph()\n",
        "        \n",
        "    def _scrape_tweets(self):\n",
        "        # construct search query based on search method and time range filters\n",
        "        if self.start_date and self.end_date:\n",
        "            date_range_query = f'since:{self.start_date} until:{self.end_date}'\n",
        "            search_query = f'{self.query} {date_range_query}'\n",
        "        else:\n",
        "            search_query = self.query\n",
        "\n",
        "        # create a scraper object based on the search method\n",
        "        if self.search_method == 'keyword':\n",
        "            scraper = sntwitter.TwitterSearchScraper(search_query)\n",
        "            extract_function = lambda tweet: re.findall(r'\\b\\w+\\b', tweet.rawContent)\n",
        "        elif self.search_method == 'hashtag':\n",
        "            scraper = sntwitter.TwitterSearchScraper(f'#{search_query}')\n",
        "            extract_function = lambda tweet: tweet.hashtags\n",
        "        elif self.search_method == 'username':\n",
        "            scraper = sntwitter.TwitterUserScraper(search_query)\n",
        "            extract_function = lambda tweet: [tweet.user.username] + tweet.mentionedUsers + [tweet.inReplyToUser]\n",
        "        elif self.search_method == 'list':\n",
        "            scraper = sntwitter.TwitterListScraper(search_query)\n",
        "            extract_function = lambda tweet: re.findall(r'\\b\\w+\\b', tweet.rawContent)\n",
        "        elif self.search_method == 'advanced':\n",
        "            scraper = sntwitter.TwitterSearchScraper(search_query)\n",
        "            extract_function = lambda tweet: re.findall(r'\\b\\w+\\b', tweet.rawContent)\n",
        "        elif self.search_method == 'location':\n",
        "            scraper = sntwitter.TwitterSearchScraper(search_query)\n",
        "            extract_function = lambda tweet: tweet.place\n",
        "        else:\n",
        "            raise ValueError(\"Invalid search_method. Must be 'keyword', 'hashtag', 'username', 'list', 'advanced', or 'location'.\")\n",
        "\n",
        "        tweets = []\n",
        "        count = 0\n",
        "        # fetch tweets until we reach the desired number of tweets\n",
        "        for tweet in scraper.get_items():\n",
        "            if count >= self.max_tweets:\n",
        "                break\n",
        "            tweets.append(tweet)\n",
        "            count += 1\n",
        "\n",
        "        # extract tweet information and create edges between users\n",
        "        for tweet in tweets:\n",
        "            users = extract_function(tweet)\n",
        "            for i, u1 in enumerate(users):\n",
        "                for u2 in users[i+1:]:\n",
        "                    self.graph.add_edge(u1, u2)\n",
        "\n",
        "        # extract tweet information\n",
        "        data = []\n",
        "        for tweet in tweets:\n",
        "            data.append({\n",
        "                'tweet_id': tweet.id,\n",
        "                'username': tweet.user.username,\n",
        "                'Replay_to':tweet.inReplyToUser,\n",
        "                'user_mentioned': tweet.mentionedUsers,\n",
        "                'retweet' : tweet.retweetedTweet,\n",
        "                'quoted_tweet' : tweet.quotedTweet,\n",
        "                'content': tweet.rawContent,\n",
        "                'date': tweet.date,\n",
        "                'retweets': tweet.retweetCount,\n",
        "                'likes': tweet.likeCount,\n",
        "                'quotes': tweet.quoteCount,\n",
        "                'replies': tweet.replyCount,\n",
        "                'url': tweet.url,\n",
        "                'place': tweet.place,\n",
        "                'hashtags': tweet.hashtags,\n",
        "                'cashtags' : tweet.cashtags\n",
        "            })\n",
        "        # Create a DataFrame from the extracted data\n",
        "        self.data = pd.DataFrame(data)\n",
        "        return data\n",
        "\n",
        "    def build_graph(self):\n",
        "        self._scrape_tweets()\n",
        "        self.graph.remove_nodes_from(list(nx.isolates(self.graph)))\n",
        "\n",
        "        # compute node positions for the graph\n",
        "        node_positions = nx.spring_layout(self.graph)\n",
        "\n",
        "        # create a dictionary that maps usernames to node positions\n",
        "        user_positions = {}\n",
        "        for node, pos in node_positions.items():\n",
        "            user_positions[node] = pos\n",
        "            self.graph.nodes[node]['pos'] = pos\n",
        "\n",
        "        return user_positions\n",
        "        \n",
        "    def visualize_graph(self):\n",
        "        # get the node positions from the built graph\n",
        "        node_positions = self.build_graph()\n",
        "\n",
        "        # create a dataframe from the node positions\n",
        "        pos_df = pd.DataFrame(node_positions, index=['x', 'y']).T\n",
        "        pos_df.index.name = 'node'\n",
        "\n",
        "        # add the node positions to the graph\n",
        "        nx.set_node_attributes(self.graph, pos_df.to_dict('index'))\n",
        "\n",
        "        # create a plotly figure object\n",
        "        fig = px.scatter(pos_df, x='x', y='y', text=pos_df.index, custom_data=[pos_df.index])\n",
        "\n",
        "        # add edges to the figure\n",
        "        for edge in self.graph.edges:\n",
        "            x0, y0 = self.graph.nodes[edge[0]]['x'], self.graph.nodes[edge[0]]['y']\n",
        "            x1, y1 = self.graph.nodes[edge[1]]['x'], self.graph.nodes[edge[1]]['y']\n",
        "            fig.add_trace(\n",
        "                go.Scatter(x=[x0, x1], y=[y0, y1], mode='lines', line=dict(color='gray'))\n",
        "            )\n",
        "\n",
        "        # configure the figure layout\n",
        "        fig.update_traces(textposition='top center', marker=dict(size=10, color='lightblue'), hovertemplate='Username: %{customdata[0]}<extra></extra>')\n",
        "        fig.update_layout(title=f'Twitter Graph for {self.query}', title_font_size=30,\n",
        "                          xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
        "                          yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
        "                          hovermode='closest')\n",
        "\n",
        "        # display the figure\n",
        "        fig.show()"
      ],
      "metadata": {
        "id": "ugbXISi0ax4i",
        "outputId": "5c2a46e7-1a42-422e-a44e-1c3e7d583573",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-109-4fc152a925c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpytz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msntwitter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnetworkx\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sntwitter'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}